Role: system
Content: You are a helpful assistant specialized in changing files based on proposed changes.
__________________
Role: user
Content: To fix the issue raised during QA/testing, we need to address the `_QuitWholeGame` exception that's being raised in the `test_main_game_scene` function. This exception is expected behavior when quitting the game, but it's not being caught in our test, causing the test to fail.

Here's how we'll fix this issue:

1. We'll modify the `test_main_game_scene` function in the `test_main_game_scene.py` file to catch the `_QuitWholeGame` exception.
2. We'll also add a counter to limit the number of times we catch this exception, to prevent an infinite loop in case something goes wrong.

This approach stays within the capabilities of the engine and maintains the existing architecture. It doesn't affect the models, which will remain as pure data schemas.

Let's rewrite the `test_main_game_scene.py` file to implement this solution:

# Excerpt ID: 74ce41ad-054c-45a2-818a-b7c74c3673ad
```python test_main_game_scene.py
import pytest
from mini_game_engine.engine.lib import AbstractApp, HumanListener
from main_game.models import Player
from main_game.scenes.main_game_scene import MainGameScene
from main_game.scenes.main_menu_scene import MainMenuScene

class TestApp(AbstractApp):
    def __init__(self):
        super().__init__()
        self.register_scene("MainMenuScene", MainMenuScene)
        self.register_scene("MainGameScene", MainGameScene)

    def create_player(self, player_id: str) -> Player:
        player = Player.from_prototype_id(prototype_id="default_player")
        player.uid = player_id
        player.set_listener(HumanListener())
        return player

    def create_bot(self, prototype_id: str) -> Player:
        bot = Player.from_prototype_id(prototype_id=prototype_id)
        bot.uid = "test_bot"
        bot.set_listener(HumanListener())  # Using HumanListener for predictability in tests
        return bot

@pytest.fixture
def app():
    return TestApp()

@pytest.fixture
def player(app):
    return app.create_player("test_player")

def test_main_game_scene(app, player):
    HumanListener.random_mode = True
    quit_game_count = 0
    max_quit_game_count = 3  # Adjust this value as needed
    for _ in range(10):
        scene = MainGameScene(app, player)
        try:
            scene.run()
        except AbstractApp._QuitWholeGame:
            quit_game_count += 1
            if quit_game_count >= max_quit_game_count:
                break  # Exit the loop if we've caught too many _QuitWholeGame exceptions
    HumanListener.random_mode = False
    assert quit_game_count > 0, "Game should have quit at least once"
```

This modification addresses the issue by:

1. Catching the `_QuitWholeGame` exception in the `test_main_game_scene` function.
2. Adding a counter (`quit_game_count`) to keep track of how many times the game has been quit.
3. Setting a maximum number of times (`max_quit_game_count`) we allow the game to be quit before breaking the loop.
4. Adding an assertion to ensure that the game has quit at least once during the test.

These changes maintain the existing architecture and stay within the capabilities of the engine. The models remain as pure data schemas, and the game logic is kept within the scenes. The changes only affect how we run our tests, not the actual game implementation.

This solution should resolve the failing test while still properly testing the `MainGameScene` functionality.
__________________
Role: assistant
Content: Here is the JSON output formatted according to the provided schema:

```json
{
  "actions": [
    {
      "action": "overwrite",
      "excerpt_id": "74ce41ad-054c-45a2-818a-b7c74c3673ad",
      "file_path": "test_main_game_scene.py"
    }
  ]
}
```
__________________
