Role: system
Content: You are a helpful assistant specialized in changing files based on proposed changes.
__________________
Role: user
Content: ## Proposed Code Change
The issue is in the test_main_game_scene.py file. The test is failing because we're not catching the _QuitWholeGame exception that's raised when the game ends. This is expected behavior - the engine documentation shows that we should catch this exception in tests.

The fix is simple: we need to modify the test to catch AbstractApp._QuitWholeGame exception alongside RandomModeGracefulExit. This matches how the engine expects graceful termination to be handled in tests.

Here's the fixed test file:

# Excerpt ID: 9b47b206-073f-49f0-a575-5225660aebcd
```python main_game/tests/test_main_game_scene.py
import pytest
from unittest.mock import patch
from mini_game_engine.engine.lib import HumanListener, RandomModeGracefulExit, AbstractApp
from main_game.scenes.main_game_scene import MainGameScene
from main_game.main import App

class TestMainGameSceneRandomRun:
    @pytest.fixture
    def app(self):
        return App()

    def test_main_game_scene_random_run(self, app):
        for i in range(10):
            print(f"starting random run iteration {i}")
            HumanListener.random_mode = True
            HumanListener.random_mode_counter = 30  # More moves needed for complex battle scene

            player = app.create_player(f"player_{i}")
            scene = MainGameScene(app, player)

            try:
                scene.run()
            except RandomModeGracefulExit:
                print(f"random mode counter reached 0 in run {i}")
            except AbstractApp._QuitWholeGame:
                print(f"game completed normally in run {i}")
            else:
                pytest.fail("Scene did not end with expected exception")
```

The changes are:
1. Added import for AbstractApp to access _QuitWholeGame
2. Added except clause to catch AbstractApp._QuitWholeGame
3. Added pytest.fail() in else clause to ensure scene ends with an expected exception
4. Improved logging messages to distinguish between different end conditions

This maintains the engine's architecture while properly handling the expected graceful termination behavior in tests. The scene itself is working correctly - it's just that we needed to handle its termination properly in the test.

## Directions
Reply with a list of actions in the following format. The response should only contain the JSON list of actions, no other text.
Make sure you are using the excerpt_id which contains the entire contents of the file.

Each action in the list must have these fields:
- action: Must be "overwrite"
- excerpt_id: The ID of the excerpt to use
- file_path: The relative path to the file

Example format for multiple files:
[
    {
        "action": "overwrite",
        "excerpt_id": "abc1",
        "file_path": "src/main.py"
    },
    {
        "action": "overwrite",
        "excerpt_id": "def2",
        "file_path": "tests/test_main.py"
    }
]
__________________
Role: assistant
Content: 
__________________
