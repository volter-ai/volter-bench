Role: system
Content: You are a helpful assistant specialized in changing files based on proposed changes.
__________________
Role: user
Content: To fix the issue raised during QA/testing, we need to address the problem in the `test_main_game_scene` function. The test is failing because the `_QuitWholeGame` exception is not being caught when the `MainMenuScene` is run after the `MainGameScene` completes.

Here's how we'll fix this issue:

1. We'll modify the `test_main_game_scene` function to catch the `_QuitWholeGame` exception.
2. We'll add a flag to track whether the game has ended, so we can verify that the game actually ran before quitting.

This approach stays within the capabilities of the engine and maintains the existing architecture. It doesn't affect the models, which will remain as pure data schemas.

Let's rewrite the `test_main_game_scene.py` file to implement this solution:

# Excerpt ID: bd497020-0398-405e-b044-f785605f95a6
```python main_game/tests/test_main_game_scene.py
import pytest
from mini_game_engine.engine.lib import AbstractApp, HumanListener
from main_game.models import Player
from main_game.scenes.main_game_scene import MainGameScene
from main_game.scenes.main_menu_scene import MainMenuScene

class TestApp(AbstractApp):
    def __init__(self):
        super().__init__()
        self.register_scene("MainMenuScene", MainMenuScene)
        self.register_scene("MainGameScene", MainGameScene)

    def create_player(self, player_id: str) -> Player:
        player = Player.from_prototype_id(prototype_id="default_player")
        player.uid = player_id
        player.set_listener(HumanListener())
        return player

    def create_bot(self, prototype_id: str) -> Player:
        bot = Player.from_prototype_id(prototype_id=prototype_id)
        bot.uid = "test_bot"
        bot.set_listener(HumanListener())  # Using HumanListener for predictability in tests
        return bot

@pytest.fixture
def app():
    return TestApp()

@pytest.fixture
def player(app):
    return app.create_player("test_player")

def test_main_game_scene(app, player):
    HumanListener.random_mode = True
    game_ended = False
    try:
        for _ in range(10):
            scene = MainGameScene(app, player)
            scene.run()
            game_ended = True
    except AbstractApp._QuitWholeGame:
        pass  # This exception is expected when quitting the game
    finally:
        HumanListener.random_mode = False
    
    assert game_ended, "The game should have run at least once before quitting"
```

This modification addresses the issue by:

1. Wrapping the entire test in a try-except block to catch the `_QuitWholeGame` exception.
2. Adding a `game_ended` flag to track whether the game actually ran before quitting.
3. Using an assertion to ensure that the game ran at least once before quitting.

These changes maintain the existing architecture and stay within the capabilities of the engine. The models remain as pure data schemas, and the game logic is kept within the scenes. The changes only affect the test execution, not the actual game implementation.

This solution should resolve the failing test while ensuring that the game actually runs before quitting.
__________________
Role: assistant
Content: ```json
{
  "actions": [
    {
      "action": "overwrite",
      "excerpt_id": "bd497020-0398-405e-b044-f785605f95a6",
      "file_path": "main_game/tests/test_main_game_scene.py"
    }
  ]
}
```
__________________
